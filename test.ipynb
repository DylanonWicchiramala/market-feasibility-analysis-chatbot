{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from tools import (\n",
    "    find_place_from_text, \n",
    "    nearby_search, \n",
    "    nearby_dense_community, \n",
    "    search_population_community_household_expenditures_data,\n",
    "    duckduckgo_search,\n",
    "    restaurant_sale_projection\n",
    ")\n",
    "from langchain_core.messages import (\n",
    "    AIMessage, \n",
    "    BaseMessage,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict, List\n",
    "from prompt import (\n",
    "    system_prompt,\n",
    "    agent_meta as agents\n",
    ")\n",
    "import functools\n",
    "\n",
    "all_tools = [restaurant_sale_projection, search_population_community_household_expenditures_data, find_place_from_text, nearby_search, nearby_dense_community, duckduckgo_search]  # Include both tools if needed\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini-2024-07-18\", \n",
    "    temperature=0, \n",
    "    top_p=0.0, \n",
    "    )\n",
    "\n",
    "## Create agents ------------------------------------------------------------------------\n",
    "def create_agent(llm, tools, system_message: str):\n",
    "    # memory = ConversationBufferMemory(memory_key='chat_history', return_messages=False)\n",
    "    \"\"\"Create an agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    #llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    agent = prompt | llm_with_tools\n",
    "    return agent\n",
    "\n",
    "\n",
    "## create agent node\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "        # result = AIMessage(**result.dict(), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "    }\n",
    "\n",
    "\n",
    "## Define state ------------------------------------------------------------------------\n",
    "# This defines the object that is passed between each node\n",
    "# in the graph. We will create different nodes for each agent and tool\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    chat_history: List[BaseMessage]\n",
    "    sender: str\n",
    "\n",
    "\n",
    "agent_name = list(agents.keys())\n",
    "\n",
    "\n",
    "analyst = agents['analyst']\n",
    "data_collector = agents['data_collector']\n",
    "reporter = agents['reporter']\n",
    "    \n",
    "analyst['node'] = create_agent(\n",
    "        llm,\n",
    "        [restaurant_sale_projection, duckduckgo_search],\n",
    "        system_message=analyst['prompt'],\n",
    "    )\n",
    "\n",
    "data_collector['node'] = create_agent(\n",
    "        llm,\n",
    "        all_tools,\n",
    "        system_message=data_collector['prompt'],\n",
    "    )\n",
    "\n",
    "reporter['node'] = create_agent(\n",
    "        llm,\n",
    "        [],\n",
    "        system_message=reporter['prompt'],\n",
    "    )\n",
    "\n",
    "analyst['node'] = functools.partial(agent_node, agent=analyst['node'], name='analyst')\n",
    "data_collector['node'] = functools.partial(agent_node, agent=data_collector['node'], name='data_collector')\n",
    "reporter['node'] = functools.partial(agent_node, agent=reporter['node'], name='reporter')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
